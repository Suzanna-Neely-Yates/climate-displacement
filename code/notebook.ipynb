{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Climate Displacement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Year\n",
    "State\n",
    "Households Inflow (Number of Returns)\n",
    "Households Outflow (Number of Returns)\n",
    "Individuals Inflow (Number of Exemptions)\n",
    "Individuals Outflow (Number of Exemptions)\n",
    "Chemical\n",
    "Dam/Levee Break\n",
    "Drought\n",
    "Earthquake\n",
    "Fire\n",
    "Flood\n",
    "Human Cause\n",
    "Hurricane\n",
    "Ice\n",
    "Mud/Landslide\n",
    "Other\n",
    "snow\n",
    "Storm\n",
    "Terrorism\n",
    "Tornado\n",
    "Tsunami\n",
    "Typhoon\n",
    "Volcano\n",
    "Water\n",
    "Winter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Folders Setup\n",
    "\n",
    "code \n",
    "    notebook.ipynb\n",
    "    data\n",
    "        Disasters\n",
    "            FEMA_dataset.csv\n",
    "        StateMigration\n",
    "            1990to1991StateMigration\n",
    "                 1990to1991StateMigrationInflow\n",
    "                     Alabama91in.xls\n",
    "                     Alaska91in.xls\n",
    "                     .\n",
    "                     .\n",
    "                     .\n",
    "                     Wisconsin91in.xls\n",
    "                     Wyoming91in.xls \n",
    "                 1990to1991StateMigrationOutflow\n",
    "                     Alabama91Out.xls\n",
    "                     Alaska91Out.xls \n",
    "                     .\n",
    "                     .\n",
    "                     .\n",
    "                     Wisconsin91Out.xls\n",
    "                     Wyoming91Out.xls \n",
    "            1991to1992StateMigration\n",
    "            1992to1993StateMigration\n",
    "            1993to1994StateMigration\n",
    "            1994to1995StateMigration\n",
    "            1995to1996StateMigration\n",
    "            1996to1997StateMigration\n",
    "            1997to1998StateMigration\n",
    "            1998to1999StateMigration\n",
    "            1999to2000StateMigration\n",
    "            2000to2001StateMigration\n",
    "            2001to2002StateMigration\n",
    "            2002to2003StateMigration\n",
    "            2003to2004StateMigration\n",
    "            2004to2005StateMigration\n",
    "            2005to2006StateMigration\n",
    "            2006to2007StateMigration\n",
    "            2007to2008StateMigration\n",
    "            2008to2009StateMigration\n",
    "            2009to2010StateMigration\n",
    "            2010to2011StateMigration \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-71eb9b797ad2>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-71eb9b797ad2>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Pseudo Code:\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Pseudo Code:\n",
    "\n",
    "FEMA Dataset Pre-Processing \n",
    "1. Create new FEMA_dataset with columns \"Year\",  \"State\" and \"Disaster Type\"\n",
    "    - contains Year, State, Disaster Type\n",
    "2. Name file \"State_Disasters_by_Year\"\n",
    "\n",
    "StateMigration Data Pre-Processing\n",
    "1. Convert all datasets in StateMigration from .xls into .csv files\n",
    "2. Extract \"Total Flow\" row with \"Number of Returns\" and \"Number of Exemptions\" - assign I if from inflow and O if from outflow - from every state file.\n",
    "3. Extract \"State\" and \"Year\" from every file\n",
    "4. Create file with \"State\" (from file name), \"Year\" (from file name), \"Number_of_Returns_I\", \"Number_of_Exemptions_I\", \"Number_of_Returns_I\" and \"Number_of_Exemptions_O\"\n",
    "5. Name file \"State Migration by Year\"\n",
    "\n",
    "Merge Datasets\n",
    "1. Merge datasets on common attributes \"Year\" and \"State\"\n",
    "2. Name dataset \"State_Migration_and_Disasters_by_Year\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-76-6f9852cb7b6d>, line 42)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-76-6f9852cb7b6d>\"\u001b[0;36m, line \u001b[0;32m42\u001b[0m\n\u001b[0;31m    # print (data.replace(data[\"Start Date\"][0], data[\"Start Date\"][1][6:10]))\u001b[0m\n\u001b[0m                                                                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "# FEMA Dataset Pre-Processing\n",
    "\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "# copy original FEMA dataset to new file\n",
    "original = r'../code/data/Disasters/FEMA_dataset.csv'\n",
    "new = r'../code/data/Disasters/State_Disasters_by_Year.csv'\n",
    "shutil.copyfile(original, new)\n",
    "\n",
    "# read csv file\n",
    "data = pd.read_csv('../code/data/Disasters/State_Disasters_by_Year.csv')\n",
    "\n",
    "# delete irrelevant rows\n",
    "data.pop('Declaration Number')\n",
    "data.pop('Declaration Type')\n",
    "data.pop('Declaration Date')\n",
    "data.pop('State')\n",
    "data.pop('County')\n",
    "data.pop('Disaster Title')\n",
    "data.pop('Close Date')\n",
    "data.pop('Individual Assistance Program')\n",
    "data.pop('Public Assistance Program')\n",
    "data.pop('Hazard Mitigation Program')\n",
    "data.pop('Individuals & Households Program')\n",
    "\n",
    "print(data)\n",
    "# <class 'pandas.core.frame.DataFrame'>\n",
    "\n",
    "#for time in data[\"Start Date\"]:\n",
    "    #data.replace(time, time[6::])\n",
    "\n",
    "    #data.replace(data[\"Start Date\"][time], data[\"Start Date\"][time][6:10])\n",
    "\n",
    "#data.loc[(data[\"Start Data\"])] = data[\"Start Date\"][6:10]\n",
    "\n",
    "#print(data)\n",
    "# print(data[\"Start Date\"][1][6::])\n",
    "print(data.replace([\"Start Date\"][1],[\"Start Date\"][1][6::])\n",
    "# print(data[\"Start Date\"][1]])\n",
    "# print(data.replace(data[\"Start Date\"][0], data[\"Start Date\"][1][6:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
